EXPERIMENT_NAME: "transformer"
DATASET:
  MODULE: "datasets.caption_dataset"
  CLASS: "FlickrDataset"
  TRAIN:
    PARAMS:
      annot_df_path: "data_files/flickr30k_images/train.csv"
      img_dir: "data_files/flickr30k_images/flickr30k_images"
  VAL:
    PARAMS:
      annot_df_path: "data_files/flickr30k_images/val.csv"
      img_dir: "data_files/flickr30k_images/flickr30k_images"
  TEST:
    PARAMS:
      annot_df_path: "data_files/flickr30k_images/test.csv"
      img_dir: "data_files/flickr30k_images/flickr30k_images"
TOKENIZER:
  MODULE: "tokenizers.word_tokenizer"
  CLASS: "WordTokenizer"
  BUILD_VOCAB_PARAMS:
    df_path: "data_files/flickr30k_images/train.csv"
    min_freq: 2
ENCODER:
  MODULE: "models.encoders"
  CLASS: "ResNet50Encoder"
  PRETRAINED: True
  PARAMS:
    fine_tune: True
DECODER:
  MODULE: "models.decoders"
  CLASS: "DecoderTransformer"
  PRETRAINED_EMBEDDINGS_PATH: "data_files/glove.6B.100d.txt"    
  PARAMS:
    feature_dim: 2048
    embed_dim: 100
    d_model: 256
    num_heads: 4
    num_layers: 6
MODEL:
  MODULE: "models.vanilla_model"
  CLASS: "VanillaCaptioningModel"
TRAINING:
  EPOCHS: 5
  BATCH_SIZE: 32
  LR: 0.0005
  WARMUP_STEPS: 3000
TESTING:
  BATCH_SIZE: 96
LOG_WANDB: True