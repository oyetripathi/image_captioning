EXPERIMENT_NAME: "relaion_pop_transformer"
DATASET:
  MODULE: "datasets.streaming_dataset"
  CLASS: "LAIONPOPDataset"
  TRAIN:
    PARAMS:
      pq_path: "data_files/laion_pop/relaion-pop/train"
      urls_per_batch: 10
      samples_per_worker: 2000
  VAL:
    PARAMS:
      pq_path: "data_files/laion_pop/relaion-pop/val"
      urls_per_batch: 10
      samples_per_worker: 200
  TEST:
    PARAMS:
      pq_path: "data_files/laion_pop/relaion-pop/test"
      urls_per_batch: 5
      samples_per_worker: 200
TOKENIZER:
  MODULE: "tokenizers.wordpiece_tokenizer"
  CLASS: "WordPieceTokenizer"
  BUILD_VOCAB_PARAMS:
    vocab_path: "data_files/laion_pop/relaion-pop/bert_base_uncased_vocab_15k.json"
ENCODER:
  MODULE: "models.encoders"
  CLASS: "ResNet101Encoder"
  PARAMS:
    fine_tune: True
DECODER:
  MODULE: "models.decoders"
  CLASS: "DecoderTransformer"
  PARAMS:
    feature_dim: 2048
    embed_dim: 128
    d_model: 512
    num_heads: 8
    num_layers: 8
MODEL:
  MODULE: "models.vanilla_model"
  CLASS: "VanillaCaptioningModel"
CHECKPOINT_NAME: "best_model_v1.pth"
TRAINING:
  EPOCHS: 4
  BATCH_SIZE: 32
  LR: 0.0001
  WARMUP_STEPS: 50
  NUM_WORKERS: 4
  AUGMENTATION:
    FLAG: True
    START_EPOCH: 0
TESTING:
  BATCH_SIZE: 16
  NUM_WORKERS: 4
LOG_WANDB: True